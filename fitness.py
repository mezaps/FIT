# -*- coding: utf-8 -*-
"""Fitness.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z5z5msP2L63kR8_mutma6KL5IzIwLrKH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

st.write(''' # ¿Eres FIT o NO? ''')
st.image("fit.jpg", caption="Descubre si eres fit o hay que cambiar algunas cosas.")

st.header('Datos de los pasajeros')

df = pd.read_csv("Fitness_Classification.csv")
df

df.info()

df.describe()

df.head()

df.shape

df.columns

df.hist(figsize=(15,10))
plt.show()

df.boxplot(figsize=(15,8))
plt.show()

df["smokes"] = df["smokes"].replace({
    "yes": 1,
    "no": 0
})

df["gender"] = df["gender"].replace({
    "M": 1,
    "F": 0
})

df.dtypes

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.show()

df.isnull().sum()

df = df.dropna()

df.isnull().sum()

df.duplicated().sum()

df = df.drop_duplicates()
df.duplicated().sum()

df["gender"].unique()
df["smokes"].unique()

df["gender"] = df["gender"].replace({
    "M": 1,
    "F": 0
})

df["smokes"] = df["smokes"].replace({
   "yes": 1,
    "no": 0,
    "Yes": 1,
    "No": 0,
    "YES": 1,
    "NO": 0
})

df.head()

df.dtypes

df.to_csv("Fitness2.csv", index=False)

y = df["is_fit"]
X = df.drop("is_fit", axis=1)

X.head()
y.head()

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size = 0.30,
    random_state = 42,
    stratify = y
)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

param_grid = {
    "max_depth": [3,4,5,6,None],
    "min_samples_split": [2,5,10],
    "min_samples_leaf": [1,2,4],
    "criterion": ["gini","entropy"]
}

dt = DecisionTreeClassifier(random_state=42)

grid_search = GridSearchCV(
    estimator=dt,
    param_grid=param_grid,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

grid_search.best_params_

dtree = grid_search.best_estimator_
dtree

from sklearn.metrics import accuracy_score, classification_report

y_pred = dtree.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicho")
plt.ylabel("Real")
plt.title("Matriz de Confusión - is_fit")
plt.show()

from sklearn.tree import plot_tree

plt.figure(figsize=(20,10))
plot_tree(
    dtree,
    feature_names = X.columns,
    class_names = ["No fit", "Fit"],
    filled=True,
    rounded=True,
    fontsize=8
)
plt.show()

from sklearn.inspection import permutation_importance

atributos = permutation_importance(
    dtree, X_train, y_train,
    n_repeats=30,
    random_state=0
)

per_dt = pd.DataFrame({
    "Atributo": X_train.columns,
    "Importancia": atributos.importances_mean,
    "Desviación std": atributos.importances_std
})

per_dt = per_dt.sort_values("Importancia", ascending=False)
per_dt

from sklearn.tree import _tree

def get_rules(tree, feature_names, class_names=None):
    tree_ = tree.tree_
    feature_name = [
        feature_names[i] if i != _tree.TREE_UNDEFINED else "undefined!"
        for i in tree_.feature
    ]

    paths = []
    path = []

    def recurse(node, path, paths):
        if tree_.feature[node] != _tree.TREE_UNDEFINED:
            name = feature_name[node]
            threshold = tree_.threshold[node]
            p1, p2 = list(path), list(path)
            p1 += [f"{name} <= {np.round(threshold,3)}"]
            recurse(tree_.children_left[node], p1, paths)
            p2 += [f"{name} > {np.round(threshold,3)}"]
            recurse(tree_.children_right[node], p2, paths)
        else:
            path += [(tree_.value[node], tree_.n_node_samples[node])]
            paths += [path]

    recurse(0, path, paths)

    samples_count = [p[-1][1] for p in paths]
    paths = [paths[i] for i in reversed(np.argsort(samples_count))]

    rules = []
    for path in paths:
        rule = "if "
        for p in path[:-1]:
            if rule != "if ":
                rule += " and "
            rule += str(p)
        rule += " then "
        if class_names is None:
            rule += "response: " + str(np.round(path[-1][0][0][0],3))
        else:
            classes = path[-1][0][0]
            l = np.argmax(classes)
            rule += f"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)"
        rule += f" | based on {path[-1][1]} samples"
        rules += [rule]
    return rules

features = X.columns
target = ["No fit", "Fit"]

rules = get_rules(dtree, features, target)
for r in rules:
    print(r)

test = pd.DataFrame({
    "age": [45],
    "height_cm": [175],
    "weight_kg": [80],
    "heart_rate": [72.0],
    "blood_pressure": [120.0],
    "sleep_hours": [7.0],
    "nutrition_quality": [6.0],
    "activity_index": [3.0],
    "smokes": [0],   # 0 = no, 1 = yes
    "gender": [1]    # 1 = M, 0 = F
})

test_pred = dtree.predict(test)


if test_pred[0] == 1:
    resultado = "FIT (apto físicamente)"
else:
    resultado = "NO FIT (no apto físicamente)"
print("Resultado interpretado:", resultado)